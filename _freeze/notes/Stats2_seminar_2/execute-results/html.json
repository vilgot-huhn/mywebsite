{
  "hash": "66a14adaf905c7565fdc6d1f5d3cc12b",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Stats2_seminar_2\"\nformat: html\ndate: 2025-02-21\nauthor: \"Vilgot Huhn\"\ncategories: [Rethinking Statistics]\nexecute:\n  freeze: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n## MN3\n\nYou test an individual M’s ability to solve a certain class of logical\nproblems. M gave answers to nine versions of the problem and you coded\neach as correct (1) or incorrect (0). This is the data:\n\n1, 0, 0, 0, 0, 1, 0, 0, 0\n\nYou want to estimate M’s true ability ( p ) using this model: $$\n\\begin{align}\ny_i &\\sim Bernoulli(p) \\\\\np &\\sim Uniform(0,1) \\\\\n\\end{align}\n$$\n\n1.  List the critical assumptions of this model.\n2.  Use grid approximation to derive point estimate and 95 %\n    Compatibility Interval (CI, defined as a highest density interval).\n3.  Verify that you obtain the same result using the binomial\n    distribution with $n = 9$, that is, equal to the number of trials\n    (this is McElreath’s approach to his globe tossing data).\n\n*Answer* Uniform prior. Independent successes. $p$ is constant (all\ntrials are equally hard).\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Rlab)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nRlab 4.0 attached.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'Rlab'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    dexp, dgamma, dweibull, pexp, pgamma, pweibull, qexp, qgamma,\n    qweibull, rexp, rgamma, rweibull\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:datasets':\n\n    precip\n```\n\n\n:::\n\n```{.r .cell-code}\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, times = 1000) #we can also use dbeta(p_grid,1,1)\nlikelihood <- dbinom(2, size = 9, prob = p_grid)#dbern(c(1, 0, 0, 0, 0, 1, 0, 0, 0),prob = p_grid)\nposterior <- likelihood * prior\nplot(p_grid,posterior, type = \"l\"); abline(v = which.max(posterior)/1000)\nd <- data.frame(\n  posterior,\n  p_grid,\n  posterior_90 = posterior > quantile(posterior, 0.1)\n)\nd[min(which(d$posterior_90 == TRUE)),]$p_grid #THERE WE GO YES\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.001001001\n```\n\n\n:::\n\n```{.r .cell-code}\nd[max(which(d$posterior_90 == TRUE)),]$p_grid #HAHA YES!\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.9009009\n```\n\n\n:::\n\n```{.r .cell-code}\nlibrary(ggplot2)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'ggplot2' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n\n```{.r .cell-code}\nggplot(d, aes(x = p_grid, y = posterior, color = posterior_90)) +\n  geom_point(size = 0.02, alpha = 0.5) #ugly\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-1-2.png){width=672}\n:::\n:::\n\n\n\nI don't know how to compute HPDI from grid really... I guess you could\nuse `quantile()` and then select based on that. **I work it out**\n\n# Exercises attempt\n\n## SR2m1\n\nRecall the globe tossing model from the chapter. Compute and plot the\ngrid approximate posterior distribution for each of the following sets\nof observations. In each case, assume a uniform prior for *p*. (1) W,W,W\n(2) W,W,W,L (3) L,W,W,L,W,W,W\n\nLet's try to trecreate the grid approximation method as a challenge:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- 20 #for granularity\n#A\nprior <- rep(1, times = g)\ngrid <- seq(from = 0, to = 1, length.out = g)\nlikelihood <- dbinom(3, size = 3, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"W,W,W\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#B\nprior <- rep(1, times = g)\ngrid <- seq(from = 0, to = 1, length.out = g)\nlikelihood <- dbinom(3, size = 4, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"W,W,W,L\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#C\nprior <- rep(1, times = g)\ngrid <- seq(from = 0, to = 1, length.out = g)\nlikelihood <- dbinom(5, size = 7, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"L,W,W,L,W,W,W\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-2-3.png){width=672}\n:::\n:::\n\n\n\n## SR2m2\n\nNow assume a prior for p that is equal to zero when p \\< 0.5 and is a\npositive constant when *p* ≥ 0.5. Again compute and plot the grid\napproximate posterior distribution for each of the sets of observations\nin the problem just above.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- 100\ngrid <- seq(from = 0, to = 1, length.out = g)\nprior <- (grid < 0.5) == FALSE #actually should be *2 to be a proper pdf\n\nlikelihood <- dbinom(3, size = 3, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"W,W,W\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlikelihood <- dbinom(3, size = 4, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"W,W,W,L\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-3-2.png){width=672}\n:::\n\n```{.r .cell-code}\nlikelihood <- dbinom(5, size = 7, prob = grid)\nposterior_unstandardized <- prior*likelihood\nposterior <- posterior_unstandardized / sum(posterior_unstandardized) #normalize\nplot(grid,posterior, type = \"l\", main = \"L,W,W,L,W,W,W\")\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-3-3.png){width=672}\n:::\n:::\n\n\n\n## SR3e3\n\nHow much posterior probability lies between p = 0.2 and p = 0.8?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\np_grid <- seq( from=0 , to=1 , length.out=1000 )\n prior <- rep( 1 , 1000 )\n likelihood <- dbinom( 6 , size=9 , prob=p_grid )\n posterior <- likelihood * prior\n posterior <- posterior / sum(posterior)\n set.seed(100)\n samples <- sample( p_grid , prob=posterior , size=1e4 , replace=TRUE )\n \nlength(samples[samples < 0.2 | samples < 0.8])/10000 #mean() works too.\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.8884\n```\n\n\n:::\n\n```{.r .cell-code}\n#To get the exact distribution. Use the beta-function and math it.\n```\n:::\n\n\n\n## SR3e4\n\n20% of the posterior probability lies below which value of *p*?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsort(samples)[2000] \n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.5185185\n```\n\n\n:::\n\n```{.r .cell-code}\nplot(sort(samples)[1:2000],seq(from = 0, to = 0.2, length.out = 2000))\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\nlibrary(rethinking)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: cmdstanr\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is cmdstanr version 0.7.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStanR documentation and vignettes: mc-stan.org/cmdstanr\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStan path: C:/Users/vilgo/Documents/.cmdstan/cmdstan-2.33.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n- CmdStan version: 2.33.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nA newer version of CmdStan is available. See ?install_cmdstan() to install it.\nTo disable this check set option or environment variable CMDSTANR_NO_VER_CHECK=TRUE.\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: posterior\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: package 'posterior' was built under R version 4.3.3\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThis is posterior version 1.6.1\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'posterior'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:stats':\n\n    mad, sd, var\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:base':\n\n    %in%, match\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nLoading required package: parallel\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrethinking (Version 2.42)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\n\nAttaching package: 'rethinking'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following objects are masked from 'package:Rlab':\n\n    dbern, rbern\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr}\n\n```\nThe following object is masked from 'package:stats':\n\n    rstudent\n```\n\n\n:::\n\n```{.r .cell-code}\ndens(samples)\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#hist(sort(samples)[2000], breaks = 1000) #don't really get why this doesn't work...\n```\n:::\n\n\n\n## SR3e6\n\nWhich values of p contain the narrowest interval equal to 66% of the\nposterior probability?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrethinking::HPDI(samples, 0.66)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n    |0.66     0.66| \n0.5085085 0.7737738 \n```\n\n\n:::\n:::\n\n\n\n## 3M6.\n\nSuppose you want to estimate the Earth’s proportion of water very\nprecisely. Specifically, you want the 99% percentile interval of the\nposterior distribution of p to be only 0.05 wide. This means the\ndistance between the upper and lower bound of the interval should be\n0.05. How many times will you have to toss the globe to do this?\n\n*First guess* There should be some variance in the n required depending\non how your draws end up, right? In simulation this would be \"simulation\nvariance\" while in sampling it would be sampling variance. My guess is\nthat this should turn out quite similar to normal standard errors, since\nwe have a flat prior. If $\\hat{p}$ is the true proportion and $x$ is the\nproportion we find in our sample of $n$ individuals, the standard error\nis $SE=\\sqrt{\\hat{p}(1-\\hat{p})/n}$, we can see here that\n$\\hat{p}(1-\\hat{p})$, meaning that the required $n$ should vary\ndepending on what $\\hat{p}$ is.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n\nThis sort of makes sense if we think of a small sample and very high\nproportion. Three \"W,W,W\" would all make the distribution only thinner\n(taller peak), while then adding a \"L\" would both make it some mix of\ntaller and wider. Visually at least this feels true to me...\n\nAnyways, to solve for a given $\\hat{p}$ we just need to plug in numbers\nto the equation and solve for $n$. So for example for $\\hat{p}=0.4$: $$\n\\begin{align}\n0.05&=2.57*\\sqrt{{0.4}(1-{0.4})/n} \\\\ \n0.05&=2.57*\\sqrt{0.24/n} \\\\ \n0.05^2&=2.57^2*\\sqrt{0.24/n}^2 \\\\ \n0.0025&=6.6049*0.24/n \\\\ \n0.0025&=1.585176/n \\\\ \n0.0025n&=1.585176 \\\\ \nn&=1.585176/0.0025 \\\\\nn &\\approx 634?\n\\end{align}\n$$\n\n2.57 is $\\approx$ the z-score in a normal distribution, so we're using\nit to get from SE to CI, which may be questionable in this case since\nwith high or low proportions the CI may exceed 1. We can find exact\nnumber with ´qnorm(0.995)´. We're assuming our error is normal.\n\nAlso 99% percentile intervals may be pretty different from 99%CI.\n\nAlso, as shown in the graph above, this equation may turn out quite\ndifferent for more skewed proportions. Also: I'm not that sure I've\ngotten the simple middle school algebra right.\n\n*Second attempt*\n\nLet's try to code the problem with a loop instead:\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.487\n```\n\n\n:::\n:::\n\n\n\nHowever it's different if *p* is very skewed.\n\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.049\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](Stats2_seminar_2_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.985\n```\n\n\n:::\n:::\n\n\n\nNotably it also turns out quite different than my questionable algebraic\nsolution.\n\n**Also:** Turns out there's a function in `rethinking` that does this.\n`PI(x,prob)` if I use samples.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamp <- sample(plausibility$grid, size = 1000, prob = plausibility$prior, replace = TRUE)\nrethinking::PI(samp, prob = 0.99)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n       1%      100% \n0.9499499 0.9959960 \n```\n\n\n:::\n:::\n\n\n\n# BTW Look at the gif I made!\n\n![](images/binom_1.gif){fig-align=\"center\" width=\"521\"}\n",
    "supporting": [
      "Stats2_seminar_2_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}