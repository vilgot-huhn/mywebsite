{
  "hash": "7872d01d1df1c485309802f98140cbdd",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Stats2_seminar_3\"\nformat: html\ndate: 2025-02-22\nauthor: \"Vilgot Huhn\"\ncategories: [Rethinking Statistics]\nexecute:\n  freeze: true\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n\n\n\n## 4M1\n \nFor the model definition below, simulate observed y values from the prior (not the posterior).\n $$\n \\begin{align}\n y_i &\\sim Normal(µ,σ) \\\\ \n µ &\\sim Normal(0,10) \\\\ \n σ &\\sim Exponential(1)\n \\end{align}\n $$\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#I think this simulates from prior.\nn <- 100\nsigma <- rexp(n, 1)\nmu <- rnorm(n, mean = 0, sd = 10)\ny <- rnorm(n, mu, sigma) #we're only plugging in values drawn from our prior.\n\ndens(y)\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n\n## 4M2. Translate the model just above into a quap formula.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflist <- alist(\n  y ~ dnorm(mu, sigma),\n  mu ~ dnorm(0, 10),\n  sigma ~ dexp(1)\n)\n```\n:::\n\n\n\n\n## 4M3. Translate the quap model formula below into a mathematical model definition.\n \n$$\n\\begin{align}\ny_i &\\sim Normal(\\mu_i,\\sigma) \\\\\n\\mu_i &= a + b*x_i \\\\\na &\\sim Normal(0,10) \\\\\nb &\\sim Uniform(0,1) \\\\\n\\sigma &\\sim Exponential(1)\n\\end{align}\n$$\n\n```{}\nflist <- alist(\n y ~ dnorm( mu , sigma ),\n mu <- a + b*x,\n a ~ dnorm( 0 , 10 ),\n b ~ dunif( 0 , 1 ),\n sigma ~ dexp( 1 )\n )\n```\n\n## 4H1. \nThe weights listed below were recorded in the!Kung census, but heights were not recorded for these individuals. Provide predicted heights and 89% intervals for each of these individuals. That is, fill in the table below, using model-based predictions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt <- data.frame(individual = 1:5, weights = c(46.95,43.72,64.78,32.59,54.63), expected_height = rep(NA, times = 5), low_89_PI = rep(NA, times = 5), high_89_PI = rep(NA, times = 5),xbar = rep(NA, times = 5))\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  individual weights expected_height low_89_PI high_89_PI xbar\n1          1   46.95              NA        NA         NA   NA\n2          2   43.72              NA        NA         NA   NA\n3          3   64.78              NA        NA         NA   NA\n4          4   32.59              NA        NA         NA   NA\n5          5   54.63              NA        NA         NA   NA\n```\n\n\n:::\n\n```{.r .cell-code}\ndata(Howell1)\nd <- Howell1\nd <- d[d$age >= 18,]\nxbar <- mean(d$weight)\n\nmdl <- quap(\n  alist(\n  height ~ dnorm(mu, sigma),\n  mu <- a + b * (weight - xbar), #where is xbar defined? Must be part of quap built in?\n  a ~ dnorm( 178, 20), \n  b ~ dlnorm(0, 1),\n  sigma ~ dunif(0,50)\n), data = d\n)\nprecis(mdl)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n             mean         sd        5.5%       94.5%\na     154.6013573 0.27030758 154.1693536 155.0333610\nb       0.9032811 0.04192362   0.8362791   0.9702831\nsigma   5.0718795 0.19115465   4.7663774   5.3773815\n```\n\n\n:::\n\n```{.r .cell-code}\n#post <- extract.samples( mdl ) \n#data <- c(46.95,43.72,64.78,32.59,54.63)\n#for (i in data) {\n # y <- rnorm( 1e5 , post$a + post$b*i , post$sigma ) \n  #print(mean(y))\n  #print(HPDI(y,prob=0.89))\n#}\n\npost <- extract.samples(mdl, n = 1000)\n\nt$expected_height <- apply(sim(mdl, data=list(weight=t$weights)),2, mean)\n#I guess we could also do it by formula.\nt$low_89_PI <- apply(sim(mdl, data=list(weight=t$weights)),2, PI)[1,]\nt$high_89_PI <- apply(sim(mdl, data=list(weight=t$weights)),2, PI)[2,]\n\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  individual weights expected_height low_89_PI high_89_PI xbar\n1          1   46.95        156.2150  147.9285   164.0839   NA\n2          2   43.72        153.2816  145.8356   162.1845   NA\n3          3   64.78        172.6121  164.2527   180.4767   NA\n4          4   32.59        143.3276  135.4016   151.6196   NA\n5          5   54.63        162.8802  155.3697   171.1801   NA\n```\n\n\n:::\n:::\n\n\n\n*Mats suggest we should do this manually too:* i.e. don't use `link()` or `sim()`\n\n## 4H2. \nSelect out all the rows in the Howell1 data with ages below 18 years of age. If you do it right, you should end up with a new data frame with 192 rows in it.\n\n1. Fit a linear regression to these data, using quap. Present and interpret the estimates. For every 10 units of increase in weight, how much taller does the model predict a child gets? `Answer: 27.18372`\n2. Plot the raw data, with height on the vertical axis and weight on the horizontal axis. Super impose the MAP regression line and 89% interval for the mean. Also superimpose the 89% interval for predicted heights.\n3. What aspects of the model fit concern you? Describe the kinds of assumptions you would change, if any, to improve the model. You don’t have to write any new code. Just explain what the model appears to be doing a bad job of, and what you hypothesize would be a better model.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#0.\ndata(Howell1)\nd <- Howell1\nd <- d[d$age < 18,]\n#\nd <- d[sample(1:nrow(d),size = 10),]\nxbar <- mean(d$weight)\n\n#1.\n#challanging to chose priors for kids 0-18. I'm going with this. A tall 18 is 190cm. So half that.\n#and I don't know what I'm talking about, so wide SD.\n#I don't know enough to mess with the other priors but something positive so I'm keeping the dlnorm(0,10)\n#and I don't know how close the relationship will be so model sigma between 0 and 10 seems fine\nmdl2 <- quap(\n  alist(\n  height ~ dnorm(mu, sigma),\n  mu <- a + b * (weight - xbar),\n  a ~ dnorm( 95, 20), \n  b ~ dlnorm(0, 1),\n  sigma ~ dunif(0,10)\n), data = d\n)\nprecis(mdl2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean        sd       5.5%      94.5%\na     112.076281 1.5129022 109.658371 114.494191\nb       3.393750 0.2158979   3.048704   3.738797\nsigma   4.795944 1.0749938   3.077896   6.513992\n```\n\n\n:::\n\n```{.r .cell-code}\nprecis(mdl2)[2,1]*10\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 33.9375\n```\n\n\n:::\n\n```{.r .cell-code}\n#2. plot MAP line and PI89\npost <- extract.samples(mdl2)\nweight.seq <- c(4:45)\nmu <- link(mdl2, data=data.frame(weight=weight.seq))\nmu.PI <- apply(mu,2,PI)\nsim.heights <- sim(mdl2, data=data.frame(weight=weight.seq), post = post)\nheight.PI <- apply(sim.heights, 2, PI, prob = 0.97)\nplot(height ~ weight, data = d, ylim = c(50,180)); curve(mean(post$a) + mean(post$b)*(x-xbar),add = TRUE); shade(mu.PI, weight.seq); shade(height.PI, weight.seq)\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#My attempt at writing an own sim() function\n#post are paired parameters drawn from the model.\nweight.seq.random <- sample(weight.seq, size = 1000, replace = TRUE)\npredicted_points <- rnorm(1000, mean = post$a + post$b*(weight.seq.random - xbar), sd = post$sigma)\nplot(weight.seq.random, predicted_points) #don't know hot to get a PI here\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-5-2.png){width=672}\n:::\n\n```{.r .cell-code}\n#seems the errors should propagate but it's not easy to see visually\n\n#second attempt. my own sim for prediction intervals\nn <- 1000\ns <- c(5:45)\npost <- rethinking::extract.samples(mdl2, n = n)\nd2f <- matrix(nrow = n, ncol = 0)\n  for(i in s){\n    d2f <- cbind(d2f,rnorm(n, mean = post$a + post$b*(s[1+i-min(s)] - xbar), sd = post$sigma))\n  } #super dumb for loop man...\nmy.sim.PI <- apply(d2f,2,PI)\nplot(my.sim.PI[2,] - my.sim.PI[1,])\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-5-3.png){width=672}\n:::\n\n```{.r .cell-code}\n#here we can see what is less clear with the naked eye\n#plot(height.PI[2,] - height.PI[1,]) \n#plot(mu.PI[2,] - mu.PI[1,]) \n```\n:::\n\n\n\n*Answer 3:* I'd be concerned about how far off the MAP-line is from the data-points, especially in the middle. The relationship looks non-linear.\n\n## 4H3. \nSuppose a colleague of yours, who works on allometry, glances at the practice problems just above. Your colleague exclaims, “That’s silly. Everyone knows that it’s only the logarithm of body weight that scales with height!” Let’s take your colleague’s advice and see what happens.\n\n(a) Model the relationship between height(cm)and the natural logarithm of weight(log-kg). Use the entire Howell1 data frame, all 544 rows, adults and non-adults. Fit this model, using quadratic approximation:\n $$\n \\begin{align}\n h_i &∼ Normal(µ_i,σ) \\\\\n µ_i &= α+βlog(w_i) \\\\\n α &∼Normal(178,20) \\\\\n β &∼Log−Normal(0,1) \\\\\n σ &∼Uniform(0,50)\n \\end{align}\n $$\nwhere $h_i$ is the height of individual i and wi is the weight (in kg) of individual i. The function for computing a natural log in R is just log. Can you interpret the resulting estimates?\n \n (b) Begin with this plot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(\"Howell1\")\nd <- Howell1\n\nmdl3 <- quap(\n  alist(\n  height ~ dnorm(mu, sigma),\n  mu <- a + b * log(weight),#note that we're not doing \"- mean(weight)\" now, it wasn't in the formula for some reason.\n  a ~ dnorm( 178, 20), \n  b ~ dlnorm(0, 1),\n  sigma ~ dunif(0,10)\n  ), data = d)\nprecis(mdl3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n            mean        sd       5.5%     94.5%\na     -22.871048 1.3343316 -25.003568 -20.73853\nb      46.816794 0.3823358  46.205748  47.42784\nsigma   5.137211 0.1558943   4.888062   5.38636\n```\n\n\n:::\n\n```{.r .cell-code}\npost <- extract.samples(mdl3) #using samples from the posterior (1)\nweight.seq <- c(4:63)\nmu <- link(mdl3, data=data.frame(weight=weight.seq))\nmu.mean <- apply(mu,2,mean)\nmu.PI <- apply(mu,2,PI, prob = 0.97)\nsim.heights <- sim(mdl3, data=data.frame(weight=weight.seq))\nheight.PI <- apply(sim.heights, 2, PI, prob = 0.97)\n\nplot(height ~ weight , data=Howell1 ,\n col=col.alpha(rangi2,0.4), main = \"97% PI for mu\", ylim = c(0,190) );  lines(weight.seq,mu.mean); shade(mu.PI, weight.seq)\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n#but it's actually cooler to do it with curve actually...\nplot(height ~ weight , data=Howell1 , col=col.alpha(rangi2,0.4), main = \"97% PI for predicted height\"  );  curve(mean(post$a) + mean(post$b) * log(x), add = TRUE);  shade(height.PI, weight.seq)\n```\n\n::: {.cell-output-display}\n![](Stats2_seminar_3_files/figure-html/unnamed-chunk-6-2.png){width=672}\n:::\n:::\n\n\n\nThen use samples from the quadratic approximate posterior of the model in (a) to superimpose on the plot: (1) the predicted mean height as a function of weight, (2) the 97% interval for the mean, and (3) the 97% interval for predicted heights.",
    "supporting": [
      "Stats2_seminar_3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}